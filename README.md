<h1 align="center" style="color:black"> Data Science Assignments </h1>

### Datasets
[Google Drive folder]([myLib/README.md](https://drive.google.com/drive/folders/1CsvJs0xZ9SCLtG4ci2dNGCkhqnI-1DLS?usp=drive_link))

### Languages and tools
<div>
  <img src="https://github.com/devicons/devicon/blob/master/icons/python/python-original.svg" title="PYTHON" alt="Python" width="60" height="60"/>&nbsp;
  <img src="https://github.com/devicons/devicon/blob/master/icons/pandas/pandas-original.svg" title="PANDAS" alt="Pandas" width="60" height="60"/>&nbsp;
</div>

## TP1 - Pandas and Data visualization

Use the Python library 'Pandas' to obtain relevant information out of a dataset. Use 'Matplotlib' and 'Seaborn' to visualize the data.

These are the tasks:
* (N1) What are the top 10 most common words for tip texts?
* (N5) Using the texts of the reviews to perform text queries and using NLP (TF-IDF) techniques, so that the "bad smell" query returns the "business_id" that has received a review about a bad smell experience in the store
* (P21) We want to know which are the sexiest businesses, for this we are going to see which are the 3 businesses with the most tips that contain the text "sexy"
* (C2) Calculate the Shannon entropy (base 2) of business category membership.
* (P28) We want to know where some of our users live. For the users who have more than 50 different business records in the reviews table get the average and standard deviation of the latitude and longitude of the businesses that rated (counting each business only once). For the user who has the least summed standard deviation of both coordinates, show that average and where it is and what the user is called
* (V7) Get exactly this visualization using the data:
  ![image](https://github.com/MarceAriel99/data-science/assets/60658991/13f06719-c31e-4002-b923-086d602dff3a)
* (V10) Get exactly this visualization using the data:
  ![image](https://github.com/MarceAriel99/data-science/assets/60658991/92b59c39-4306-46f3-9d85-e31a2222a362)
* (Part 2) Make 6 interesting visualizations with the datasets provided.

## TP2

Use the Python library 'Spark' to obtain relevant information out of a dataset.

These are the tasks:
* (S2) What is the state with the best average rating for their businesses? Why?
* (S16) What is the most complaining user by state? We consider a user who has more than 5 reviews and they are all 2 stars or less to be complaining.
* (S17) Get the average antiquity of users and the name of the most antique user whose last review contains the word 'pizza'
* (S41) Using the texts of the reviews and the NLP (TF-IDF) techniques so that the query is 'high quality', return the name of the pizzeria, the review and the city, which has been recognized for the quality of its products.

## TP3

Use machine learning models to explain and predict the 'popular' variable for the dataset provided.
